{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c07de536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests as requests\n",
    "import time as time\n",
    "import hmac\n",
    "import hashlib\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec2af959",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('BTC_with_Gold_USD_minute.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e1c8d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FeatureEngineering(df):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import requests as requests\n",
    "    import time as time\n",
    "    import hmac\n",
    "    import hashlib\n",
    "    import os\n",
    "    from datetime import datetime, timedelta\n",
    "    from dotenv import load_dotenv\n",
    "    import json\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    df[\"btc_return\"] = df[\"close\"].pct_change()\n",
    "    df[\"gold_return\"] = df[\"gold_close_gc=f\"].pct_change()\n",
    "    df[\"usd_return\"] = df[\"usd_close_dx=f\"].pct_change()\n",
    "    window = 60\n",
    "    df[\"btc_momentum\"] = df[\"btc_return\"].rolling(window).mean()\n",
    "    df[\"btc_volatility\"] = df[\"btc_return\"].rolling(window).std()\n",
    "    df[\"btc_volume_mean\"] = df[\"volume\"].rolling(window).mean()\n",
    "\n",
    "    df[\"gold_momentum\"] = df[\"gold_return\"].rolling(window).mean()\n",
    "    df[\"gold_volatility\"] = df[\"gold_return\"].rolling(window).std()\n",
    "\n",
    "    df[\"usd_momentum\"] = df[\"usd_return\"].rolling(window).mean()\n",
    "    df[\"usd_volatility\"] = df[\"usd_return\"].rolling(window).std()\n",
    "    df[\"target\"] = df[\"btc_return\"].shift(-1)\n",
    "    drop_cols = [\n",
    "    \"open\", \"high\", \"low\", \"close\", \"volume\",\n",
    "    \"gold_open_gc=f\", \"gold_high_gc=f\", \"gold_low_gc=f\", \"gold_close_gc=f\", \"gold_volume_gc=f\",\n",
    "    \"usd_open_dx=f\", \"usd_high_dx=f\", \"usd_low_dx=f\", \"usd_close_dx=f\", \"usd_volume_dx=f\"\n",
    "    ]\n",
    "    df = df.drop(columns=[c for c in drop_cols if c in df.columns])\n",
    "    cols = ['btc_return', 'gold_return', 'usd_return', 'btc_momentum',\n",
    "       'btc_volatility', 'btc_volume_mean', 'gold_momentum', 'gold_volatility',\n",
    "       'usd_momentum', 'usd_volatility', 'target', 'time']\n",
    "    df = df.copy()\n",
    "    df[cols] = (df[cols]\n",
    "                .replace([\"\", \"nan\", \"NaN\"], pd.NA)\n",
    "                .ffill()\n",
    "                .bfill()) \n",
    "    for lag in [1, 2, 3, 6, 12, 24]:\n",
    "        df[f'btc_return_lag_{lag}'] = df['btc_return'].shift(lag)\n",
    "        df[f'btc_volatility_lag_{lag}'] = df['btc_volatility'].shift(lag)\n",
    "\n",
    "    windows = [3, 6, 12, 24]\n",
    "    for w in windows:\n",
    "        df[f'btc_return_rolling_mean_{w}'] = df['btc_return'].rolling(w).mean()\n",
    "        df[f'btc_return_rolling_std_{w}'] = df['btc_return'].rolling(w).std()\n",
    "        df[f'btc_momentum_rolling_mean_{w}'] = df['btc_momentum'].rolling(w).mean()\n",
    "    \n",
    "    df['btc_gold_corr_6h'] = df['btc_return'].rolling(6).corr(df['gold_return'])\n",
    "    df['btc_usd_corr_6h'] = df['btc_return'].rolling(6).corr(df['usd_return'])\n",
    "    df['btc_gold_spread'] = df['btc_return'] - df['gold_return']\n",
    "    df['btc_usd_spread'] = df['btc_return'] - df['usd_return']\n",
    "    df['btc_gold_momentum_diff'] = df['btc_momentum'] - df['gold_momentum']\n",
    "    df['btc_usd_momentum_diff'] = df['btc_momentum'] - df['usd_momentum']\n",
    "    df['btc_volatility_sqrt'] = np.sqrt(df['btc_volatility'])\n",
    "    df['btc_momentum_sq'] = df['btc_momentum'] ** 2\n",
    "    df['log_btc_volume'] = np.log1p(df['btc_volume_mean'])\n",
    "    df['vol_mom_ratio'] = df['btc_momentum'] / (df['btc_volatility'] + 1e-6)\n",
    "    df['risk_on'] = ((df['gold_return'] < 0) & (df['btc_return'] > 0)).astype(int)\n",
    "    df['risk_off'] = ((df['gold_return'] > 0) & (df['btc_return'] < 0)).astype(int)\n",
    "\n",
    "    corr_matrix = df.drop(columns=['time']).corr().abs()\n",
    "    high_corr_features = set()\n",
    "\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i+1, len(corr_matrix.columns)):\n",
    "            if (corr_matrix.iloc[i, j] > 0.95):\n",
    "                high_corr_features.add(corr_matrix.columns[j])\n",
    "    features_to_drop = list(high_corr_features)\n",
    "    df_cleaned = df.drop(columns=features_to_drop)\n",
    "    final_df=df_cleaned\n",
    "    final_df['target'] =   final_df['btc_return'].rolling(12).std().shift(-12)\n",
    "    final_df['high_vol_regime'] = (final_df['btc_volatility'] > final_df['btc_volatility'].rolling(24).mean()).astype(int)\n",
    "    final_df['trend_regime'] = (final_df['btc_return_rolling_mean_24'] > 0).astype(int)\n",
    "    cols = ['btc_return', 'gold_return', 'usd_return', 'btc_momentum',\n",
    "       'btc_volatility', 'btc_volume_mean', 'gold_momentum', 'gold_volatility',\n",
    "       'usd_momentum', 'usd_volatility', 'target', 'time',\n",
    "       'btc_return_lag_1', 'btc_return_lag_2', 'btc_return_lag_3',\n",
    "       'btc_return_lag_6', 'btc_return_lag_12', 'btc_volatility_lag_12',\n",
    "       'btc_return_lag_24', 'btc_volatility_lag_24',\n",
    "       'btc_return_rolling_mean_3', 'btc_return_rolling_std_3',\n",
    "       'btc_return_rolling_mean_6', 'btc_return_rolling_std_6',\n",
    "       'btc_return_rolling_mean_12', 'btc_return_rolling_std_12',\n",
    "       'btc_return_rolling_mean_24', 'btc_return_rolling_std_24',\n",
    "       'btc_gold_corr_6h', 'btc_usd_corr_6h', 'btc_gold_spread',\n",
    "       'btc_gold_momentum_diff', 'btc_volatility_sqrt', 'btc_momentum_sq',\n",
    "       'log_btc_volume', 'vol_mom_ratio', 'risk_on', 'risk_off']\n",
    "    final_df = final_df.copy()\n",
    "    final_df[cols] = (final_df[cols]\n",
    "                .replace([\"\", \"nan\", \"NaN\"], pd.NA)\n",
    "                .ffill()\n",
    "                .bfill())\n",
    "    return final_df\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dbbf1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eacc74e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new=FeatureEngineering(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae3fb16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104000, 40)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77471f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "btc_return",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gold_return",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "usd_return",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_momentum",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_volatility",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_volume_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gold_momentum",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gold_volatility",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "usd_momentum",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "usd_volatility",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "target",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_return_lag_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_return_lag_2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_return_lag_3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_return_lag_6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_return_lag_12",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_volatility_lag_12",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_return_lag_24",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_volatility_lag_24",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_return_rolling_mean_3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_return_rolling_std_3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_return_rolling_mean_6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_return_rolling_std_6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_return_rolling_mean_12",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_return_rolling_std_12",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_return_rolling_mean_24",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_return_rolling_std_24",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_gold_corr_6h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_usd_corr_6h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_gold_spread",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_gold_momentum_diff",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_volatility_sqrt",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_momentum_sq",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "log_btc_volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "vol_mom_ratio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "risk_on",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "risk_off",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "high_vol_regime",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "trend_regime",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "7c37ebe7-57da-47df-b833-ce5330568589",
       "rows": [
        [
         "count",
         "103939.0",
         "103939.0",
         "103939.0",
         "103939.0",
         "103939.0",
         "103939.0",
         "103939.0",
         "103939.0",
         "103939.0",
         "103939.0",
         "103939.0",
         "103939.0",
         "103939.0",
         "103939.0",
         "103939.0",
         "103939.0",
         "103939.0",
         "103939.0",
         "103939.0",
         "103939.0",
         "103939.0",
         "103939.0",
         "103939.0",
         "103939.0",
         "103939.0",
         "103939.0",
         "103939.0",
         "103939.0",
         "103939.0",
         "103939.0",
         "103939.0",
         "103939.0",
         "103939.0",
         "103939.0",
         "103939.0",
         "103939.0",
         "103939.0",
         "103939.0",
         "103939.0"
        ],
        [
         "mean",
         "2.6619991197670662e-06",
         "1.9375915580626757e-06",
         "6.793156504844443e-08",
         "2.6732340409057123e-06",
         "0.0004964380260520508",
         "104.36088907917143",
         "2.0023297254111862e-06",
         "0.00022758112267316018",
         "6.438786871202764e-08",
         "8.60649767160387e-05",
         "0.00045596313659507226",
         "2.653483125983645e-06",
         "2.6563133413299027e-06",
         "2.659998981285499e-06",
         "2.6739982009592017e-06",
         "2.687262114483786e-06",
         "0.0004963883009398552",
         "2.7117231107970745e-06",
         "0.0004963292047988699",
         "2.654736851030873e-06",
         "0.0003985914611324419",
         "2.6618207369024106e-06",
         "0.00043457363232577345",
         "2.656191752496522e-06",
         "0.00045593992629667363",
         "2.677695826319145e-06",
         "0.000473137584502346",
         "-0.025640036154649895",
         "0.021994031445927337",
         "7.244075617043905e-07",
         "6.709043154945263e-07",
         "0.021314362132198915",
         "7.532202687947606e-09",
         "4.432803319810845",
         "0.0037446171231289723",
         "0.003867653142708704",
         "0.003954242392172332",
         "0.4803971560242065",
         "0.4999663264029864"
        ],
        [
         "std",
         "0.0007041509457458005",
         "0.00040922394302555376",
         "0.0001535055854666664",
         "8.674750086996137e-05",
         "0.0004999847690893165",
         "85.69749954145941",
         "5.272249227890445e-05",
         "0.0003409249116788181",
         "1.975428217934572e-05",
         "0.00012711990792784163",
         "0.0005386104985525276",
         "0.0007041443815875409",
         "0.0007041441930786569",
         "0.0007041437148819367",
         "0.0007041376840822431",
         "0.0007041061387762733",
         "0.000499944828214991",
         "0.000704039372083207",
         "0.0004998922569130652",
         "0.00040356090659222514",
         "0.0005835798148007581",
         "0.0002838413038162461",
         "0.0005562844707740726",
         "0.0001983583260717857",
         "0.0005386013272720646",
         "0.0001388078711475178",
         "0.0005228591948409077",
         "0.4905701301342164",
         "0.49612915874593116",
         "0.0008398242747314809",
         "0.00010525132451227438",
         "0.006491255529170925",
         "6.024553260024351e-08",
         "0.6474825683288608",
         "0.11642669880498298",
         "0.06207037513268835",
         "0.06275861895454526",
         "0.4996179841549033",
         "0.5000024041403689"
        ],
        [
         "min",
         "-0.0790647496939898",
         "-0.021819183575973344",
         "-0.012825715125755699",
         "-0.0013805248461339625",
         "0.0",
         "0.0",
         "-0.0003727007599299022",
         "0.0",
         "-0.0002154526934236567",
         "0.0",
         "0.0",
         "-0.0790647496939898",
         "-0.0790647496939898",
         "-0.0790647496939898",
         "-0.0790647496939898",
         "-0.0790647496939898",
         "0.0",
         "-0.0790647496939898",
         "0.0",
         "-0.026637012481150024",
         "0.0",
         "-0.013446971907958091",
         "0.0",
         "-0.006681339299250614",
         "0.0",
         "-0.003333133389637463",
         "0.0",
         "-0.9999859123711617",
         "-0.9998616800727556",
         "-0.08840016900863423",
         "-0.0015361151680447032",
         "0.0",
         "0.0",
         "0.0",
         "-0.43096969714706423",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "25%",
         "-0.0002363138547867849",
         "0.0",
         "0.0",
         "-3.089282887049072e-05",
         "0.0003117486305679593",
         "52.833333333333336",
         "-1.635906493100044e-05",
         "5.7688621453118194e-05",
         "-6.76113688716969e-06",
         "1.947709628566226e-05",
         "0.0002735609296602387",
         "-0.0002363138547867849",
         "-0.0002363138547867849",
         "-0.00023630653260847678",
         "-0.00023630118795192612",
         "-0.0002362681005151357",
         "0.0003117486305679593",
         "-0.00023622140865087182",
         "0.0003117486305679593",
         "-0.00014041076475784786",
         "0.00017907515803991352",
         "-0.00010093205142254018",
         "0.00024103742686939304",
         "-7.098237112089512e-05",
         "0.0002735609296602387",
         "-5.019969447143021e-05",
         "0.00029258521880607205",
         "-0.39963335206514117",
         "-0.36788161467177866",
         "-0.00024004670384036864",
         "-3.6735101429765296e-05",
         "0.017656404802971412",
         "2.2447733816827946e-10",
         "3.9858928539946015",
         "-0.07880902952877757",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "50%",
         "0.0",
         "0.0",
         "0.0",
         "1.3829439328538751e-06",
         "0.0004069954411812142",
         "77.38333333333334",
         "0.0",
         "0.00014104901069416858",
         "0.0",
         "5.318053458105961e-05",
         "0.0003777862752888888",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0004069954411812142",
         "0.0",
         "0.0004069954411812142",
         "1.3255663973884186e-09",
         "0.00030842633718827035",
         "0.0",
         "0.0003558253017297585",
         "-1.7494498407340706e-07",
         "0.0003777862752888888",
         "1.9189515425751164e-08",
         "0.0003932533759722474",
         "-0.02763285472988222",
         "-0.007683606346620827",
         "0.0",
         "8.411381771526271e-07",
         "0.020174128015386792",
         "1.0430294114970883e-09",
         "4.361611319722948",
         "0.003633572494500614",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "75%",
         "0.00023864135943252318",
         "0.0",
         "0.0",
         "3.360671739976451e-05",
         "0.000549333903909654",
         "124.11666666666666",
         "1.9721453175976698e-05",
         "0.00027144516723180066",
         "7.600785409334066e-06",
         "0.00011112799954385262",
         "0.0005322328353885281",
         "0.0002386199548627399",
         "0.0002386199548627399",
         "0.0002386199548627399",
         "0.0002386199548627399",
         "0.00023860872838321612",
         "0.000549333903909654",
         "0.00023859321105057507",
         "0.000549333903909654",
         "0.000142642638832254",
         "0.0005028584132521965",
         "0.0001032169206688823",
         "0.000522555313797411",
         "7.379688393747974e-05",
         "0.0005322328353885281",
         "5.275352297507557e-05",
         "0.0005350377069858051",
         "0.3566098594704275",
         "0.4007624187633241",
         "0.00024180260747230786",
         "4.018433238394033e-05",
         "0.023437873280415102",
         "3.515788995532548e-09",
         "4.829246635350902",
         "0.08457835891776058",
         "0.0",
         "0.0",
         "1.0",
         "1.0"
        ],
        [
         "max",
         "0.06547883971592783",
         "0.03752448870196967",
         "0.013802379151481636",
         "0.001121748719531157",
         "0.010235909201486688",
         "925.9666666666667",
         "0.0006254081450328279",
         "0.004853868014564749",
         "0.00023765935746925538",
         "0.0017846155459653808",
         "0.0228961496111492",
         "0.06547883971592783",
         "0.06547883971592783",
         "0.06547883971592783",
         "0.06547883971592783",
         "0.06547883971592783",
         "0.010235909201486688",
         "0.06547883971592783",
         "0.010235909201486688",
         "0.022016681582704867",
         "0.04594554662324047",
         "0.011143057434624922",
         "0.032429680687434286",
         "0.005491357316603329",
         "0.0228961496111492",
         "0.0027437150653955023",
         "0.0161757675405077",
         "0.9999879219351242",
         "0.999987921935124",
         "0.07445150860269889",
         "0.0012980257451764823",
         "0.10117267023009073",
         "1.905848850793201e-06",
         "6.831917606630955",
         "0.514209434846134",
         "1.0",
         "1.0",
         "1.0",
         "1.0"
        ]
       ],
       "shape": {
        "columns": 39,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>btc_return</th>\n",
       "      <th>gold_return</th>\n",
       "      <th>usd_return</th>\n",
       "      <th>btc_momentum</th>\n",
       "      <th>btc_volatility</th>\n",
       "      <th>btc_volume_mean</th>\n",
       "      <th>gold_momentum</th>\n",
       "      <th>gold_volatility</th>\n",
       "      <th>usd_momentum</th>\n",
       "      <th>usd_volatility</th>\n",
       "      <th>...</th>\n",
       "      <th>btc_gold_spread</th>\n",
       "      <th>btc_gold_momentum_diff</th>\n",
       "      <th>btc_volatility_sqrt</th>\n",
       "      <th>btc_momentum_sq</th>\n",
       "      <th>log_btc_volume</th>\n",
       "      <th>vol_mom_ratio</th>\n",
       "      <th>risk_on</th>\n",
       "      <th>risk_off</th>\n",
       "      <th>high_vol_regime</th>\n",
       "      <th>trend_regime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>103939.000000</td>\n",
       "      <td>103939.000000</td>\n",
       "      <td>1.039390e+05</td>\n",
       "      <td>103939.000000</td>\n",
       "      <td>103939.000000</td>\n",
       "      <td>103939.000000</td>\n",
       "      <td>103939.000000</td>\n",
       "      <td>103939.000000</td>\n",
       "      <td>1.039390e+05</td>\n",
       "      <td>103939.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.039390e+05</td>\n",
       "      <td>1.039390e+05</td>\n",
       "      <td>103939.000000</td>\n",
       "      <td>1.039390e+05</td>\n",
       "      <td>103939.000000</td>\n",
       "      <td>103939.000000</td>\n",
       "      <td>103939.000000</td>\n",
       "      <td>103939.000000</td>\n",
       "      <td>103939.000000</td>\n",
       "      <td>103939.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>6.793157e-08</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>104.360889</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>6.438787e-08</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>...</td>\n",
       "      <td>7.244076e-07</td>\n",
       "      <td>6.709043e-07</td>\n",
       "      <td>0.021314</td>\n",
       "      <td>7.532203e-09</td>\n",
       "      <td>4.432803</td>\n",
       "      <td>0.003745</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.003954</td>\n",
       "      <td>0.480397</td>\n",
       "      <td>0.499966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>1.535056e-04</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>85.697500</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>1.975428e-05</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>...</td>\n",
       "      <td>8.398243e-04</td>\n",
       "      <td>1.052513e-04</td>\n",
       "      <td>0.006491</td>\n",
       "      <td>6.024553e-08</td>\n",
       "      <td>0.647483</td>\n",
       "      <td>0.116427</td>\n",
       "      <td>0.062070</td>\n",
       "      <td>0.062759</td>\n",
       "      <td>0.499618</td>\n",
       "      <td>0.500002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.079065</td>\n",
       "      <td>-0.021819</td>\n",
       "      <td>-1.282572e-02</td>\n",
       "      <td>-0.001381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.154527e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.840017e-02</td>\n",
       "      <td>-1.536115e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.430970</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.000236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>52.833333</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>-6.761137e-06</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.400467e-04</td>\n",
       "      <td>-3.673510e-05</td>\n",
       "      <td>0.017656</td>\n",
       "      <td>2.244773e-10</td>\n",
       "      <td>3.985893</td>\n",
       "      <td>-0.078809</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>77.383333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.411382e-07</td>\n",
       "      <td>0.020174</td>\n",
       "      <td>1.043029e-09</td>\n",
       "      <td>4.361611</td>\n",
       "      <td>0.003634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>124.116667</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>7.600785e-06</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>...</td>\n",
       "      <td>2.418026e-04</td>\n",
       "      <td>4.018433e-05</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>3.515789e-09</td>\n",
       "      <td>4.829247</td>\n",
       "      <td>0.084578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.065479</td>\n",
       "      <td>0.037524</td>\n",
       "      <td>1.380238e-02</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.010236</td>\n",
       "      <td>925.966667</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.004854</td>\n",
       "      <td>2.376594e-04</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>...</td>\n",
       "      <td>7.445151e-02</td>\n",
       "      <td>1.298026e-03</td>\n",
       "      <td>0.101173</td>\n",
       "      <td>1.905849e-06</td>\n",
       "      <td>6.831918</td>\n",
       "      <td>0.514209</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows √ó 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          btc_return    gold_return    usd_return   btc_momentum  \\\n",
       "count  103939.000000  103939.000000  1.039390e+05  103939.000000   \n",
       "mean        0.000003       0.000002  6.793157e-08       0.000003   \n",
       "std         0.000704       0.000409  1.535056e-04       0.000087   \n",
       "min        -0.079065      -0.021819 -1.282572e-02      -0.001381   \n",
       "25%        -0.000236       0.000000  0.000000e+00      -0.000031   \n",
       "50%         0.000000       0.000000  0.000000e+00       0.000001   \n",
       "75%         0.000239       0.000000  0.000000e+00       0.000034   \n",
       "max         0.065479       0.037524  1.380238e-02       0.001122   \n",
       "\n",
       "       btc_volatility  btc_volume_mean  gold_momentum  gold_volatility  \\\n",
       "count   103939.000000    103939.000000  103939.000000    103939.000000   \n",
       "mean         0.000496       104.360889       0.000002         0.000228   \n",
       "std          0.000500        85.697500       0.000053         0.000341   \n",
       "min          0.000000         0.000000      -0.000373         0.000000   \n",
       "25%          0.000312        52.833333      -0.000016         0.000058   \n",
       "50%          0.000407        77.383333       0.000000         0.000141   \n",
       "75%          0.000549       124.116667       0.000020         0.000271   \n",
       "max          0.010236       925.966667       0.000625         0.004854   \n",
       "\n",
       "       usd_momentum  usd_volatility  ...  btc_gold_spread  \\\n",
       "count  1.039390e+05   103939.000000  ...     1.039390e+05   \n",
       "mean   6.438787e-08        0.000086  ...     7.244076e-07   \n",
       "std    1.975428e-05        0.000127  ...     8.398243e-04   \n",
       "min   -2.154527e-04        0.000000  ...    -8.840017e-02   \n",
       "25%   -6.761137e-06        0.000019  ...    -2.400467e-04   \n",
       "50%    0.000000e+00        0.000053  ...     0.000000e+00   \n",
       "75%    7.600785e-06        0.000111  ...     2.418026e-04   \n",
       "max    2.376594e-04        0.001785  ...     7.445151e-02   \n",
       "\n",
       "       btc_gold_momentum_diff  btc_volatility_sqrt  btc_momentum_sq  \\\n",
       "count            1.039390e+05        103939.000000     1.039390e+05   \n",
       "mean             6.709043e-07             0.021314     7.532203e-09   \n",
       "std              1.052513e-04             0.006491     6.024553e-08   \n",
       "min             -1.536115e-03             0.000000     0.000000e+00   \n",
       "25%             -3.673510e-05             0.017656     2.244773e-10   \n",
       "50%              8.411382e-07             0.020174     1.043029e-09   \n",
       "75%              4.018433e-05             0.023438     3.515789e-09   \n",
       "max              1.298026e-03             0.101173     1.905849e-06   \n",
       "\n",
       "       log_btc_volume  vol_mom_ratio        risk_on       risk_off  \\\n",
       "count   103939.000000  103939.000000  103939.000000  103939.000000   \n",
       "mean         4.432803       0.003745       0.003868       0.003954   \n",
       "std          0.647483       0.116427       0.062070       0.062759   \n",
       "min          0.000000      -0.430970       0.000000       0.000000   \n",
       "25%          3.985893      -0.078809       0.000000       0.000000   \n",
       "50%          4.361611       0.003634       0.000000       0.000000   \n",
       "75%          4.829247       0.084578       0.000000       0.000000   \n",
       "max          6.831918       0.514209       1.000000       1.000000   \n",
       "\n",
       "       high_vol_regime   trend_regime  \n",
       "count    103939.000000  103939.000000  \n",
       "mean          0.480397       0.499966  \n",
       "std           0.499618       0.500002  \n",
       "min           0.000000       0.000000  \n",
       "25%           0.000000       0.000000  \n",
       "50%           0.000000       0.000000  \n",
       "75%           1.000000       1.000000  \n",
       "max           1.000000       1.000000  \n",
       "\n",
       "[8 rows x 39 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "05e5001f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gold_return",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "14a4ba23-e488-4fd4-a786-602846543d89",
       "rows": [
        [
         "60",
         null
        ],
        [
         "61",
         "0.0"
        ],
        [
         "62",
         "0.0"
        ],
        [
         "63",
         "0.0"
        ],
        [
         "64",
         "0.0"
        ],
        [
         "65",
         "0.0"
        ],
        [
         "66",
         "0.0"
        ],
        [
         "67",
         "0.0"
        ],
        [
         "68",
         "0.0"
        ],
        [
         "69",
         "0.0"
        ],
        [
         "70",
         "0.0"
        ],
        [
         "71",
         "0.0"
        ],
        [
         "72",
         "0.0"
        ],
        [
         "73",
         "0.0"
        ],
        [
         "74",
         "0.0"
        ],
        [
         "75",
         "0.0"
        ],
        [
         "76",
         "0.0"
        ],
        [
         "77",
         "0.0"
        ],
        [
         "78",
         "0.0"
        ],
        [
         "79",
         "0.0"
        ],
        [
         "80",
         "0.0"
        ],
        [
         "81",
         "0.0"
        ],
        [
         "82",
         "0.0"
        ],
        [
         "83",
         "0.0"
        ],
        [
         "84",
         "0.0"
        ],
        [
         "85",
         "0.0"
        ],
        [
         "86",
         "0.0"
        ],
        [
         "87",
         "0.0"
        ],
        [
         "88",
         "0.0"
        ],
        [
         "89",
         "0.0"
        ],
        [
         "90",
         "0.0"
        ],
        [
         "91",
         "0.0"
        ],
        [
         "92",
         "0.0"
        ],
        [
         "93",
         "0.0"
        ],
        [
         "94",
         "0.0"
        ],
        [
         "95",
         "0.0"
        ],
        [
         "96",
         "0.0"
        ],
        [
         "97",
         "0.0"
        ],
        [
         "98",
         "0.0"
        ],
        [
         "99",
         "0.0"
        ],
        [
         "100",
         "0.0"
        ],
        [
         "101",
         "0.0"
        ],
        [
         "102",
         "0.0"
        ],
        [
         "103",
         "0.0"
        ],
        [
         "104",
         "0.0"
        ],
        [
         "105",
         "0.0"
        ],
        [
         "106",
         "0.0"
        ],
        [
         "107",
         "0.0"
        ],
        [
         "108",
         "0.0"
        ],
        [
         "109",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 103939
       }
      },
      "text/plain": [
       "60        NaN\n",
       "61        0.0\n",
       "62        0.0\n",
       "63        0.0\n",
       "64        0.0\n",
       "         ... \n",
       "103994    0.0\n",
       "103995    0.0\n",
       "103996    0.0\n",
       "103997    0.0\n",
       "103998    0.0\n",
       "Name: gold_return, Length: 103939, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gold_return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f98ece65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class FeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass \n",
    "    def fit(self, X, y=None):\n",
    "        return self  \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X = FeatureEngineering(X)  \n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cd0ceff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "from scipy.stats.mstats import winsorize\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "def apply_scaler(final_df, scaler=None, fit=False):\n",
    "    scaler = RobustScaler()\n",
    "    scaled = scaler.fit_transform(final_df.select_dtypes(include=np.number))\n",
    "    final_df_scaled = pd.DataFrame(scaled, columns=final_df.select_dtypes(include=np.number).columns)\n",
    "    def cap_outliers(df, cols=None, lower=0.01, upper=0.99):\n",
    "        df_capped = df.copy()\n",
    "        if cols is None:\n",
    "            cols = df.select_dtypes(include=np.number).columns\n",
    "        for col in cols:\n",
    "            lower_val = df_capped[col].quantile(lower)\n",
    "            upper_val = df_capped[col].quantile(upper)\n",
    "            df_capped[col] = np.clip(df_capped[col], lower_val, upper_val)\n",
    "        return df_capped\n",
    "    df_capped = cap_outliers(final_df_scaled, lower=0.02, upper=0.98)\n",
    "    for col in df_capped.columns:\n",
    "        if df_capped[col].dtype != 'object':  \n",
    "            df_capped[col] = winsorize(df_capped[col], limits=[0.05, 0.05])\n",
    "    scaler = RobustScaler()\n",
    "    scaled_df = pd.DataFrame(scaler.fit_transform(df_capped), columns=df_capped.columns)\n",
    "    for col in ['btc_volume_mean', 'btc_volatility', 'btc_momentum_sq', 'btc_volatility_sqrt']:\n",
    "        df_capped[col] = np.log1p(df_capped[col])\n",
    "    return df_capped,scaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eea7857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomScaler(BaseEstimator, TransformerMixin):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from scipy.stats.mstats import winsorize\n",
    "    from sklearn.base import BaseEstimator, TransformerMixin\n",
    "    from sklearn.preprocessing import RobustScaler\n",
    "    def __init__(self, lower=0.02, upper=0.98, winsorize_limits=(0.05, 0.05), log_features=None):\n",
    "        self.lower = lower\n",
    "        self.upper = upper\n",
    "        self.winsorize_limits = winsorize_limits\n",
    "        self.log_features = log_features or ['btc_volume_mean', 'btc_volatility', 'btc_momentum_sq', 'btc_volatility_sqrt']\n",
    "        self.scaler = RobustScaler()\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        X_num = X.select_dtypes(include=np.number)\n",
    "        X_capped = self._cap_outliers(X_num)\n",
    "        X_wins = self._apply_winsorize(X_capped)\n",
    "        self.scaler.fit(X_wins)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_num = X.select_dtypes(include=np.number)\n",
    "        X_capped = self._cap_outliers(X_num)\n",
    "        X_wins = self._apply_winsorize(X_capped)\n",
    "        X_scaled = pd.DataFrame(self.scaler.transform(X_wins), columns=X_wins.columns, index=X_wins.index)\n",
    "        \n",
    "        for col in self.log_features:\n",
    "            if col in X_scaled.columns:\n",
    "                X_scaled[col] = np.log1p(X_scaled[col].clip(lower=0))\n",
    "        \n",
    "        X_rest = X.select_dtypes(exclude=np.number)\n",
    "        X_final = pd.concat([X_scaled, X_rest], axis=1)\n",
    "        \n",
    "        return X_final\n",
    "    \n",
    "    def _cap_outliers(self, df):\n",
    "        df_capped = df.copy()\n",
    "        for col in df.columns:\n",
    "            lower_val = df_capped[col].quantile(self.lower)\n",
    "            upper_val = df_capped[col].quantile(self.upper)\n",
    "            df_capped[col] = np.clip(df_capped[col], lower_val, upper_val)\n",
    "        return df_capped\n",
    "    \n",
    "    def _apply_winsorize(self, df):\n",
    "        df_wins = df.copy()\n",
    "        for col in df.columns:\n",
    "            df_wins[col] = winsorize(df_wins[col], limits=self.winsorize_limits)\n",
    "        return df_wins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f980db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('features', FeatureEngineer()),   \n",
    "    ('scaler', CustomScaler())         \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c02233b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "def get_time_series_splits(X, y, n_splits=3):\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    splits = []\n",
    "    \n",
    "    for train_idx, val_idx in tscv.split(X):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        splits.append((X_train, X_val, y_train, y_val))\n",
    "    \n",
    "    return splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ad833d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = FeatureEngineering(df)\n",
    "X = CustomScaler().fit_transform(X)\n",
    "y = X['target']\n",
    "X = X.drop(columns=['target'])\n",
    "splits = get_time_series_splits(X, y, n_splits=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5de98240",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor, ExtraTreesRegressor   \n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "\n",
    "models = {\n",
    "    'DecisionTree': DecisionTreeRegressor(random_state=42),\n",
    "    'RandomForest': RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "    'ExtraTrees': ExtraTreesRegressor(random_state=42, n_jobs=-1),\n",
    "    'AdaBoost': AdaBoostRegressor(random_state=42),\n",
    "    'GradientBoosting': GradientBoostingRegressor(random_state=42),\n",
    "    'XGB': XGBRegressor(random_state=42, n_jobs=-1),\n",
    "    'LGBM': LGBMRegressor(random_state=42, n_jobs=-1)\n",
    "}\n",
    "param_grids = {\n",
    "    'DecisionTree': {'max_depth':[5,10,15], 'min_samples_split':[2,5,10], 'min_samples_leaf':[1,3,5]},\n",
    "    'RandomForest': {'n_estimators':[100,200], 'max_depth':[None,10,20], 'min_samples_split':[2,5,10], 'min_samples_leaf':[1,3,5]},\n",
    "    'ExtraTrees': {'n_estimators':[100,200], 'max_depth':[None,10,20], 'min_samples_split':[2,5,10]},\n",
    "    'AdaBoost': {'n_estimators':[50,100,200], 'learning_rate':[0.01,0.05,0.1]},\n",
    "    'GradientBoosting': {'n_estimators':[100,200], 'learning_rate':[0.01,0.05,0.1], 'max_depth':[3,4,5]},\n",
    "    'XGB': {'n_estimators':[100,200,300], 'learning_rate':[0.01,0.05,0.1], 'max_depth':[4,6,8]},\n",
    "    'LGBM': {'n_estimators':[100,200,300], 'learning_rate':[0.01,0.05,0.1], 'num_leaves':[31,50,70]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a0de2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def tune_models(X, y, models, param_grids, n_iter=15, n_splits=3, scoring='r2'):\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    results = []\n",
    "    best_models = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nüîπ Tuning {name}...\")\n",
    "        if name not in param_grids:\n",
    "            print(f\"‚ö†Ô∏è No param grid found for {name}, skipping...\")\n",
    "            continue\n",
    "\n",
    "        search = RandomizedSearchCV(\n",
    "            model,\n",
    "            param_distributions=param_grids[name],\n",
    "            n_iter=n_iter,\n",
    "            cv=tscv,\n",
    "            scoring=scoring,\n",
    "            n_jobs=-1,\n",
    "            random_state=42,\n",
    "            refit=True,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        search.fit(X, y)\n",
    "        best_models[name] = search.best_estimator_\n",
    "\n",
    "        results.append({\n",
    "            'Model': name,\n",
    "            'Best Score': search.best_score_,\n",
    "            'Best Params': search.best_params_\n",
    "        })\n",
    "\n",
    "    results_df = pd.DataFrame(results).sort_values(by='Best Score', ascending=False)\n",
    "    return results_df, best_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f146a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_tuner_dir\\volatility_nn_tuning\\tuner0.json\n",
      "\n",
      "Best Hyperparameters:\n",
      "units_input: 192\n",
      "dropout_input: 0.30000000000000004\n",
      "units_hidden1: 96\n",
      "dropout_hidden1: 0.4\n",
      "units_hidden2: 64\n",
      "learning_rate: 0.000791524243562959\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naman\\OneDrive\\Desktop\\delta_Exchange_india\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2599/2599\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.0597 - mae: 0.1408 - val_loss: 0.0015 - val_mae: 0.0285\n",
      "Epoch 2/100\n",
      "\u001b[1m2599/2599\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 5.6190e-04 - mae: 0.0153 - val_loss: 1.4983e-05 - val_mae: 0.0029\n",
      "Epoch 3/100\n",
      "\u001b[1m2599/2599\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 3.0120e-06 - mae: 9.9343e-04 - val_loss: 8.5993e-07 - val_mae: 3.8041e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m2599/2599\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 2.1404e-06 - mae: 9.2639e-04 - val_loss: 2.4630e-06 - val_mae: 0.0012\n",
      "Epoch 5/100\n",
      "\u001b[1m2599/2599\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 4.8657e-06 - mae: 0.0014 - val_loss: 2.2057e-05 - val_mae: 0.0039\n",
      "Epoch 6/100\n",
      "\u001b[1m2599/2599\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 4.6320e-06 - mae: 0.0014 - val_loss: 1.2523e-06 - val_mae: 6.3673e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m2599/2599\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 2.4709e-06 - mae: 0.0011 - val_loss: 1.3997e-06 - val_mae: 7.4086e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m2599/2599\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.3721e-06 - mae: 8.0148e-04 - val_loss: 1.0774e-06 - val_mae: 5.0300e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m2599/2599\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 6.5666e-07 - mae: 5.2005e-04 - val_loss: 1.0202e-06 - val_mae: 5.3835e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m2599/2599\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 5.0759e-07 - mae: 4.1561e-04 - val_loss: 8.4831e-07 - val_mae: 3.7144e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m2599/2599\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 4.5464e-07 - mae: 3.8376e-04 - val_loss: 8.4483e-07 - val_mae: 3.6728e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m2599/2599\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 4.4780e-07 - mae: 3.7999e-04 - val_loss: 8.3710e-07 - val_mae: 3.5706e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m2599/2599\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 4.5193e-07 - mae: 3.8191e-04 - val_loss: 8.3718e-07 - val_mae: 3.5722e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m2599/2599\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 4.3961e-07 - mae: 3.7434e-04 - val_loss: 8.4083e-07 - val_mae: 3.6226e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m2599/2599\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 4.4267e-07 - mae: 3.8003e-04 - val_loss: 8.9968e-07 - val_mae: 4.2743e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m2599/2599\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 4.4171e-07 - mae: 3.7924e-04 - val_loss: 8.4391e-07 - val_mae: 3.6683e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m2599/2599\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 4.4296e-07 - mae: 3.7611e-04 - val_loss: 8.3833e-07 - val_mae: 3.5893e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m2599/2599\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 4.3866e-07 - mae: 3.7499e-04 - val_loss: 8.4466e-07 - val_mae: 3.6708e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m2599/2599\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 4.4121e-07 - mae: 3.7858e-04 - val_loss: 8.3770e-07 - val_mae: 3.5804e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m2599/2599\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 4.3793e-07 - mae: 3.7625e-04 - val_loss: 8.4787e-07 - val_mae: 3.7096e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m2599/2599\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 4.3850e-07 - mae: 3.7667e-04 - val_loss: 8.9493e-07 - val_mae: 4.2259e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m2599/2599\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 4.4065e-07 - mae: 3.7818e-04 - val_loss: 8.9766e-07 - val_mae: 4.2538e-04\n",
      "\u001b[1m650/650\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\n",
      "üìä Model Performance Comparison:\n",
      "                 Model  R2_Score\n",
      "0  NeuralNetwork_Tuned -0.000736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\naman\\AppData\\Local\\Temp\\ipykernel_8864\\3719458086.py:119: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, new_row], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import keras_tuner as kt\n",
    "\n",
    "# -----------------------------\n",
    "# Data cleaning and preparation\n",
    "# -----------------------------\n",
    "df = df.dropna(subset=['target'])\n",
    "df = df.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "X = df.drop(columns=['target', 'time']).values\n",
    "y = df['target'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Neural Network Tuning Function\n",
    "# -----------------------------\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(\n",
    "            hp.Int('units_input', 64, 256, step=32),\n",
    "            activation='relu',\n",
    "            input_shape=(X_train.shape[1],)\n",
    "        ),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(hp.Float('dropout_input', 0.1, 0.5, step=0.1)),\n",
    "\n",
    "        layers.Dense(\n",
    "            hp.Int('units_hidden1', 32, 128, step=32),\n",
    "            activation='relu'\n",
    "        ),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(hp.Float('dropout_hidden1', 0.1, 0.5, step=0.1)),\n",
    "\n",
    "        layers.Dense(\n",
    "            hp.Int('units_hidden2', 32, 128, step=32),\n",
    "            activation='relu'\n",
    "        ),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Float('learning_rate', 1e-4, 1e-2, sampling='log')\n",
    "        ),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# -----------------------------\n",
    "# Keras Tuner Search\n",
    "# -----------------------------\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_mae',\n",
    "    max_trials=15,\n",
    "    executions_per_trial=1,\n",
    "    directory='my_tuner_dir',\n",
    "    project_name='volatility_nn_tuning'\n",
    ")\n",
    "\n",
    "tuner.search(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Best Model Training\n",
    "# -----------------------------\n",
    "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "for k, v in best_hp.values.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "best_model = tuner.hypermodel.build(best_hp)\n",
    "best_model.fit(\n",
    "    X_scaled, y,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Evaluation\n",
    "# -----------------------------\n",
    "y_pred_nn = best_model.predict(X_val).flatten()\n",
    "y_pred_nn = np.nan_to_num(y_pred_nn)\n",
    "r2_nn = r2_score(y_val, y_pred_nn)\n",
    "\n",
    "# -----------------------------\n",
    "# Combine results with other models\n",
    "# -----------------------------\n",
    "# If results_df from your sklearn models exists, use it\n",
    "# Otherwise, initialize a new one\n",
    "try:\n",
    "    results_df\n",
    "except NameError:\n",
    "    results_df = pd.DataFrame(columns=['Model', 'R2_Score'])\n",
    "\n",
    "new_row = pd.DataFrame([{'Model': 'NeuralNetwork_Tuned', 'R2_Score': r2_nn}])\n",
    "results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "print(\"\\nüìä Model Performance Comparison:\")\n",
    "print(results_df.sort_values(by='R2_Score', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d67f13f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "import joblib\n",
    "\n",
    "class ModelSelectionPipeline:\n",
    "    def __init__(self, models, param_grids, scaler=None, cv_splits=5):\n",
    "        self.models = models\n",
    "        self.param_grids = param_grids\n",
    "        self.scaler = scaler or StandardScaler()\n",
    "        self.cv = TimeSeriesSplit(n_splits=cv_splits)\n",
    "        self.results = []\n",
    "        self.best_models = {}\n",
    "\n",
    "    def preprocess(self, X):\n",
    "        return self.scaler.fit_transform(X)\n",
    "    \n",
    "    def tune_sklearn_models(self, X, y):\n",
    "        for name, model in self.models.items():\n",
    "            print(f\"Tuning {name}...\")\n",
    "            search = RandomizedSearchCV(\n",
    "                model,\n",
    "                param_distributions=self.param_grids[name],\n",
    "                n_iter=15,\n",
    "                cv=self.cv,\n",
    "                scoring='r2',\n",
    "                n_jobs=-1,\n",
    "                random_state=42,\n",
    "                refit=True,\n",
    "                verbose=0\n",
    "            )\n",
    "            search.fit(X, y)\n",
    "            self.best_models[name] = search.best_estimator_\n",
    "            self.results.append({\n",
    "                'Model': name,\n",
    "                'Best Score': search.best_score_,\n",
    "                'Best Params': search.best_params_\n",
    "            })\n",
    "\n",
    "    def tune_neural_network(self, X_train, X_val, y_train, y_val, build_model_fn):\n",
    "        tuner = kt.RandomSearch(\n",
    "            build_model_fn,\n",
    "            objective='val_mae',\n",
    "            max_trials=15,\n",
    "            executions_per_trial=1,\n",
    "            directory='tuner_results',\n",
    "            project_name='nn_tuning'\n",
    "        )\n",
    "\n",
    "        tuner.search(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=50,\n",
    "            batch_size=32,\n",
    "            callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "        best_nn = build_model_fn(best_hp)\n",
    "        best_nn.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=50,\n",
    "            batch_size=32,\n",
    "            callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        y_pred = best_nn.predict(X_val).flatten()\n",
    "        r2_nn = r2_score(y_val, y_pred)\n",
    "        self.best_models['NeuralNetwork'] = best_nn\n",
    "        self.results.append({'Model': 'NeuralNetwork', 'Best Score': r2_nn, 'Best Params': best_hp.values})\n",
    "\n",
    "    def get_results(self):\n",
    "        df = pd.DataFrame(self.results).sort_values(by='Best Score', ascending=False)\n",
    "        self.best_model_name = df.iloc[0]['Model']\n",
    "        print(df)\n",
    "        print(f\"\\nBest model overall: {self.best_model_name}\")\n",
    "        return df\n",
    "\n",
    "    def save_best_model(self):\n",
    "        best_model = self.best_models[self.best_model_name]\n",
    "        if self.best_model_name == 'NeuralNetwork':\n",
    "            best_model.save('best_model.h5')\n",
    "        else:\n",
    "            joblib.dump(best_model, 'best_model.pkl')\n",
    "        print(\"‚úÖ Model saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5dde8e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning DecisionTree...\n",
      "Tuning RandomForest...\n",
      "Tuning ExtraTrees...\n",
      "Tuning AdaBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naman\\OneDrive\\Desktop\\delta_Exchange_india\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 9 is smaller than n_iter=15. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning GradientBoosting...\n",
      "Tuning XGB...\n",
      "Tuning LGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006538 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 103939, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naman\\OneDrive\\Desktop\\delta_Exchange_india\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\naman\\OneDrive\\Desktop\\delta_Exchange_india\\.venv\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "\u001b[1m650/650\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "              Model  Best Score  \\\n",
      "3          AdaBoost   -0.000267   \n",
      "7     NeuralNetwork   -0.002166   \n",
      "6              LGBM   -0.022943   \n",
      "5               XGB   -0.026073   \n",
      "0      DecisionTree   -0.144092   \n",
      "2        ExtraTrees   -0.607332   \n",
      "1      RandomForest   -0.652553   \n",
      "4  GradientBoosting   -1.392748   \n",
      "\n",
      "                                         Best Params  \n",
      "3        {'n_estimators': 50, 'learning_rate': 0.01}  \n",
      "7  {'units_input': 224, 'dropout_input': 0.4, 'un...  \n",
      "6  {'num_leaves': 31, 'n_estimators': 100, 'learn...  \n",
      "5  {'n_estimators': 100, 'max_depth': 4, 'learnin...  \n",
      "0  {'min_samples_split': 10, 'min_samples_leaf': ...  \n",
      "2  {'n_estimators': 200, 'min_samples_split': 10,...  \n",
      "1  {'n_estimators': 100, 'min_samples_split': 5, ...  \n",
      "4  {'n_estimators': 100, 'max_depth': 3, 'learnin...  \n",
      "\n",
      "Best model overall: AdaBoost\n",
      "‚úÖ Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "pipeline = ModelSelectionPipeline(models, param_grids)\n",
    "X_scaled = pipeline.preprocess(X)\n",
    "pipeline.tune_sklearn_models(X_scaled, y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "pipeline.tune_neural_network(X_train, X_val, y_train, y_val, build_model)\n",
    "results_df = pipeline.get_results()\n",
    "pipeline.save_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ccb44bab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m      4\u001b[39m     best_model = joblib.load(\u001b[33m'\u001b[39m\u001b[33mbest_model.pkl\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m X_new_scaled = pipeline.scaler.transform(\u001b[43mX_new\u001b[49m)\n\u001b[32m      6\u001b[39m y_pred = best_model.predict(X_new_scaled)\n",
      "\u001b[31mNameError\u001b[39m: name 'X_new' is not defined"
     ]
    }
   ],
   "source": [
    "if pipeline.best_model_name == 'NeuralNetwork':\n",
    "    best_model = keras.models.load_model('best_model.h5')\n",
    "else:\n",
    "    best_model = joblib.load('best_model.pkl')\n",
    "X_new_scaled = pipeline.scaler.transform(X_new)\n",
    "y_pred = best_model.predict(X_new_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84a2678c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Best Score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Best Params",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "3869a539-23fd-4353-8917-601a0468f5be",
       "rows": [
        [
         "3",
         "AdaBoost",
         "-0.00026666699624087185",
         "{'n_estimators': 50, 'learning_rate': 0.01}"
        ],
        [
         "7",
         "NeuralNetwork",
         "-0.002165887933551991",
         "{'units_input': 224, 'dropout_input': 0.4, 'units_hidden1': 64, 'dropout_hidden1': 0.4, 'units_hidden2': 96, 'learning_rate': 0.0005060145942181329}"
        ],
        [
         "6",
         "LGBM",
         "-0.02294297238442764",
         "{'num_leaves': 31, 'n_estimators': 100, 'learning_rate': 0.01}"
        ],
        [
         "5",
         "XGB",
         "-0.02607273265633898",
         "{'n_estimators': 100, 'max_depth': 4, 'learning_rate': 0.01}"
        ],
        [
         "0",
         "DecisionTree",
         "-0.14409204756512234",
         "{'min_samples_split': 10, 'min_samples_leaf': 3, 'max_depth': 5}"
        ],
        [
         "2",
         "ExtraTrees",
         "-0.6073320844987358",
         "{'n_estimators': 200, 'min_samples_split': 10, 'max_depth': 10}"
        ],
        [
         "1",
         "RandomForest",
         "-0.6525528586523249",
         "{'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_depth': 10}"
        ],
        [
         "4",
         "GradientBoosting",
         "-1.3927478297356026",
         "{'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.01}"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Score</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>-0.000267</td>\n",
       "      <td>{'n_estimators': 50, 'learning_rate': 0.01}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NeuralNetwork</td>\n",
       "      <td>-0.002166</td>\n",
       "      <td>{'units_input': 224, 'dropout_input': 0.4, 'un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>-0.022943</td>\n",
       "      <td>{'num_leaves': 31, 'n_estimators': 100, 'learn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGB</td>\n",
       "      <td>-0.026073</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 4, 'learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>-0.144092</td>\n",
       "      <td>{'min_samples_split': 10, 'min_samples_leaf': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>-0.607332</td>\n",
       "      <td>{'n_estimators': 200, 'min_samples_split': 10,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>-0.652553</td>\n",
       "      <td>{'n_estimators': 100, 'min_samples_split': 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>-1.392748</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 3, 'learnin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model  Best Score  \\\n",
       "3          AdaBoost   -0.000267   \n",
       "7     NeuralNetwork   -0.002166   \n",
       "6              LGBM   -0.022943   \n",
       "5               XGB   -0.026073   \n",
       "0      DecisionTree   -0.144092   \n",
       "2        ExtraTrees   -0.607332   \n",
       "1      RandomForest   -0.652553   \n",
       "4  GradientBoosting   -1.392748   \n",
       "\n",
       "                                         Best Params  \n",
       "3        {'n_estimators': 50, 'learning_rate': 0.01}  \n",
       "7  {'units_input': 224, 'dropout_input': 0.4, 'un...  \n",
       "6  {'num_leaves': 31, 'n_estimators': 100, 'learn...  \n",
       "5  {'n_estimators': 100, 'max_depth': 4, 'learnin...  \n",
       "0  {'min_samples_split': 10, 'min_samples_leaf': ...  \n",
       "2  {'n_estimators': 200, 'min_samples_split': 10,...  \n",
       "1  {'n_estimators': 100, 'min_samples_split': 5, ...  \n",
       "4  {'n_estimators': 100, 'max_depth': 3, 'learnin...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317e614d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mfinal_df\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'final_df' is not defined"
     ]
    }
   ],
   "source": [
    "final_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ac2921",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
